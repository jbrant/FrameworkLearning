[HEADER]
[HEADER:DATASOURCE]
rawFile=FILE_RAW
sourceFile=
sourceFormat=
sourceHeaders=f
[SETUP]
[SETUP:CONFIG]
allowedClasses=integer,string
csvFormat=decpnt|comma
inputHeaders=f
maxClassCount=50
[SETUP:FILENAMES]
FILE_RANDOMIZE=abalone_random.data
FILE_TRAIN=abalone_train.data
FILE_RAW=src\main\resources\Abalone\abalone.data
FILE_TRAINSET=abalone_train.egb
FILE_CLUSTER=abalone_cluster.data
FILE_OUTPUT=abalone_output.data
FILE_EVAL=abalone_eval.data
FILE_ML=abalone_train.eg
FILE_NORMALIZE=abalone_norm.data
FILE_EVAL_NORM=abalone_eval_norm.data
[DATA]
[DATA:CONFIG]
goal=classification
[DATA:STATS]
"name","isclass","iscomplete","isint","isreal","amax","amin","mean","sdev","source"
"field:1",1,1,0,0,0.0001,-0.0001,0,0,""
"field:2",0,1,0,1,0.815,0.075,0.5239920996,0.1200785362,""
"field:3",0,1,0,1,0.65,0.055,0.4078812545,0.0992279861,""
"field:4",0,1,0,1,1.13,0,0.1395163993,0.0418220495,""
"field:5",0,1,0,1,2.8255,0.002,0.8287421594,0.4903303136,""
"field:6",0,1,0,1,1.488,0.001,0.3593674886,0.2219363778,""
"field:7",0,1,0,1,0.76,0.0005,0.1805936079,0.1096011283,""
"field:8",0,1,0,1,1.005,0.0015,0.2388308595,0.1391860055,""
"field:9",1,1,1,1,29,1,9.9336844625,3.2237830658,""
[DATA:CLASSES]
"field","code","name","count"
"field:1","F","F",1307
"field:1","I","I",1342
"field:1","M","M",1528
"field:9","1","1",1
"field:9","10","10",634
"field:9","11","11",487
"field:9","12","12",267
"field:9","13","13",203
"field:9","14","14",126
"field:9","15","15",103
"field:9","16","16",67
"field:9","17","17",58
"field:9","18","18",42
"field:9","19","19",32
"field:9","2","2",1
"field:9","20","20",26
"field:9","21","21",14
"field:9","22","22",6
"field:9","23","23",9
"field:9","24","24",2
"field:9","25","25",1
"field:9","26","26",1
"field:9","27","27",2
"field:9","29","29",1
"field:9","3","3",15
"field:9","4","4",57
"field:9","5","5",115
"field:9","6","6",259
"field:9","7","7",391
"field:9","8","8",568
"field:9","9","9",689
[NORMALIZE]
[NORMALIZE:CONFIG]
missingValues=DiscardMissing
sourceFile=FILE_TRAIN
targetFile=FILE_NORMALIZE
[NORMALIZE:RANGE]
"name","io","timeSlice","action","high","low"
"field:1","input",0,"equilateral",1,-1
"field:2","input",0,"range",1,-1
"field:3","input",0,"range",1,-1
"field:4","input",0,"range",1,-1
"field:5","input",0,"range",1,-1
"field:6","input",0,"range",1,-1
"field:7","input",0,"range",1,-1
"field:8","input",0,"range",1,-1
"field:9","output",0,"equilateral",1,-1
[PROCESS]
[PROCESS:CONFIG]
backwardSize=
forwardSize=
sourceFile=
targetFile=
[PROCESS:FIELDS]
"name","command"
[RANDOMIZE]
[RANDOMIZE:CONFIG]
sourceFile=FILE_RAW
targetFile=FILE_RANDOMIZE
[CLUSTER]
[CLUSTER:CONFIG]
clusters=28
sourceFile=FILE_EVAL
targetFile=FILE_CLUSTER
type=kmeans
[BALANCE]
[BALANCE:CONFIG]
balanceField=
countPer=
sourceFile=
targetFile=
[CODE]
[CODE:CONFIG]
embedData=f
targetFile=FILE_CODE
targetLanguage=NOGENERATION
[SEGREGATE]
[SEGREGATE:CONFIG]
sourceFile=FILE_RANDOMIZE
[SEGREGATE:FILES]
"file","percent"
"FILE_TRAIN",75
"FILE_EVAL",25
[GENERATE]
[GENERATE:CONFIG]
sourceFile=FILE_NORMALIZE
targetFile=FILE_TRAINSET
[ML]
[ML:CONFIG]
architecture=?:B->TANH->13:B->TANH->?
evalFile=FILE_EVAL
machineLearningFile=FILE_ML
outputFile=FILE_OUTPUT
query=
trainingFile=FILE_TRAINSET
type=feedforward
[ML:TRAIN]
arguments=
cross=
targetError=0.05
type=rprop
[ML:OPCODES]
"code","count"
[TASKS]
[TASKS:task-cluster]
cluster
[TASKS:task-code]
code
[TASKS:task-create]
create
[TASKS:task-evaluate]
evaluate
[TASKS:task-evaluate-raw]
set ML.CONFIG.evalFile="FILE_EVAL_NORM"
set NORMALIZE.CONFIG.sourceFile="FILE_EVAL"
set NORMALIZE.CONFIG.targetFile="FILE_EVAL_NORM"
normalize
evaluate-raw
[TASKS:task-full]
randomize
segregate
normalize
generate
create
train
evaluate
[TASKS:task-generate]
randomize
segregate
normalize
generate
[TASKS:task-train]
train
